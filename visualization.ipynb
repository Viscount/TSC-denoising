{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "seasons = pd.read_csv(\"./data/bangumi.csv\", delimiter=\",\", encoding=\"utf-8\")\n",
    "episodes = pd.read_csv(\"./data/episode.csv\", delimiter=\",\", encoding=\"utf-8\")\n",
    "danmaku_complete = pd.read_csv(\"./data/danmaku_complete.csv\", delimiter=\"\\t\", encoding=\"utf-8\", quoting=csv.QUOTE_NONE, low_memory=False)\n",
    "danmaku_complete = danmaku_complete.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选出候选的episode中的弹幕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'danmakus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-98f2d2c80cb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdanmaku_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdanmakus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdanmakus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m173248\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'danmakus' is not defined"
     ]
    }
   ],
   "source": [
    "danmaku_select = danmakus[danmakus['episode_id'] == 173248]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入embedding模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166544\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "word_model = Word2Vec.load(\"./models/dm_word2vec_200.model\")\n",
    "word_dim = 200\n",
    "print(len(word_model.wv.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分词预处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as segtool\n",
    "import re\n",
    "\n",
    "ACCEPTABLE_TYPE = {'n', 't', 's', 'f', 'v', 'a', 'b', 'z', 'e', 'y', 'o'}\n",
    "REPLACE_DICT = {\n",
    "    \"233+\": \"233\",\n",
    "    \"666+\": \"666\"\n",
    "}\n",
    "\n",
    "def check_type(word_type):\n",
    "    if word_type[0] in ACCEPTABLE_TYPE:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_replace(word):\n",
    "    for item in REPLACE_DICT.keys():\n",
    "        pattern = re.compile(item)\n",
    "        if re.match(pattern, word) is not None:\n",
    "            new_word = REPLACE_DICT[item]\n",
    "            return new_word\n",
    "    return word\n",
    "\n",
    "def word_segment(content):\n",
    "    words = []\n",
    "    results = segtool.cut(content)\n",
    "    for result in results:\n",
    "        result.word = check_replace(result.word)\n",
    "        if check_type(result.flag):\n",
    "            words.append(result.word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "窗口划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_slice(danmaku, start, end):\n",
    "    window_danmaku = danmaku[(start <= danmaku.playback_time) & (danmaku.playback_time<= end)]\n",
    "    return window_danmaku.sort_values(by='playback_time')\n",
    "\n",
    "selected_window = window_slice(danmaku_select, 400, 410)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danmaku_feature = {}\n",
    "for index, row in selected_window.iterrows():\n",
    "    words = word_split(row['content'])\n",
    "    count = 0\n",
    "    sum = np.zeros(word_dim)\n",
    "    if len(words) == 0:\n",
    "        continue\n",
    "    for word in words:\n",
    "        if word in word_model.wv.vocab:\n",
    "            sum += word_model.wv[word]\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        danmaku_feature[row['tsc_raw_id']] = sum/count\n",
    "len(danmaku_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较相似度，画出矩阵图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "num = len(danmaku_feature)\n",
    "sim_matrix = np.zeros((num, num), dtype=float)\n",
    "x_index = 0\n",
    "for index, row in selected_window.iterrows():\n",
    "    dmid = row['tsc_raw_id']\n",
    "    if dmid in danmaku_feature:\n",
    "        x_feature = danmaku_feature[dmid]\n",
    "        y_index = 0\n",
    "        for index_, row_ in selected_window.iterrows():\n",
    "            dmid_ = row_['tsc_raw_id']\n",
    "            if dmid_ in danmaku_feature:\n",
    "                y_feature = danmaku_feature[dmid_]\n",
    "                sim_matrix[x_index, y_index] = pdist(np.vstack([x_feature,y_feature]),'cosine')\n",
    "                y_index += 1\n",
    "        x_index += 1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (15.0, 8.0)\n",
    "\n",
    "plt.matshow(sim_matrix, cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机投影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(danmaku_feature)\n",
    "rand = np.random.RandomState(42) \n",
    "X = np.zeros((num, word_dim), dtype=float)\n",
    "y = np.zeros(num, dtype=int)\n",
    "x_index = 0\n",
    "for index, row in selected_window.iterrows():\n",
    "    dmid = row['tsc_raw_id']\n",
    "    if dmid in danmaku_feature:\n",
    "        x_feature = danmaku_feature[dmid]\n",
    "        X[x_index] = x_feature\n",
    "        flag = danmaku_complete[danmaku_complete['tsc_raw_id'] == dmid]['block_level'].iloc[0]\n",
    "        y[x_index] = int(flag)\n",
    "        x_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = rand.randint(X.shape[1], size=2)\n",
    "plt.scatter(X[:, i], X[:, j], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lpproj import LocalityPreservingProjection\n",
    "lpp = LocalityPreservingProjection(n_components=2)\n",
    "\n",
    "X_2D = lpp.fit_transform(X)\n",
    "plt.scatter(X_2D[:, 0], X_2D[:, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research]",
   "language": "python",
   "name": "conda-env-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
